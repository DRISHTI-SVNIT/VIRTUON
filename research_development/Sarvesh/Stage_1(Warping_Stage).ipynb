{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lxeb8eSh4hSu"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "import matplotlib as plt\r\n",
        "from tensorflow import keras \r\n",
        "from tensorflow.keras.layers import Conv2D, concatenate, Dropout,MaxPool2D, MaxPooling2D, Conv2DTranspose, Activation, BatchNormalization,UpSampling2D, Add"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cwSrXLgFAcW"
      },
      "source": [
        "arr1 = np.random.randn(1,128,128,18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlF1B6Tu7hhV"
      },
      "source": [
        "#Build the model\r\n",
        "def conv_2d_block (x,n_filters,k_size,batchnorm = False):\r\n",
        "#1st layer\r\n",
        "  x= Conv2D(filters=n_filters,kernel_size=(k_size,k_size) ,padding='same', kernel_initializer = 'he_normal')(x)\r\n",
        "  if batchnorm:\r\n",
        "    x= BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "#2nd Layer\r\n",
        "  x= Conv2D(filters=n_filters,kernel_size=(k_size,k_size) ,padding='same', kernel_initializer = 'he_normal')(x)\r\n",
        "  if batchnorm:\r\n",
        "    x= BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "\r\n",
        "  return x\r\n",
        " \r\n",
        "def clothing_encoder(inputs,n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\r\n",
        "  c1 = conv_2d_block(inputs,n_filters*1,conv_k_size,batchnorm)  \r\n",
        "  p1 = MaxPool2D(pool_size=(pool_size,pool_size))(c1)\r\n",
        "  p1 = Dropout(dropout)(p1)\r\n",
        "  \r\n",
        "  c2 = conv_2d_block(p1,n_filters*2,conv_k_size,batchnorm)  \r\n",
        "  p2 = MaxPool2D(pool_size=(pool_size,pool_size))(c2)\r\n",
        "  p2 = Dropout(dropout)(p2)\r\n",
        "\r\n",
        "  c3 = conv_2d_block(p2,n_filters*4,conv_k_size,batchnorm)  \r\n",
        "  p3 = MaxPool2D(pool_size=(pool_size,pool_size))(c3)\r\n",
        "  p3 = Dropout(dropout)(p3)\r\n",
        "\r\n",
        "  c4 = conv_2d_block(p3,n_filters*8,conv_k_size,batchnorm)  \r\n",
        "  p4 = MaxPool2D(pool_size=(pool_size,pool_size))(c4)\r\n",
        "  p4 = Dropout(dropout)(p4)\r\n",
        "\r\n",
        "  c5 = conv_2d_block(p4,n_filters*16,conv_k_size,batchnorm)  \r\n",
        "  p5 = MaxPool2D(pool_size=(pool_size,pool_size))(c5)\r\n",
        "  p5 = Dropout(dropout)(p5)\r\n",
        "\r\n",
        "  c6 = conv_2d_block(p5,n_filters*32,conv_k_size,batchnorm)  \r\n",
        "  p6 = MaxPool2D(pool_size=(pool_size,pool_size))(c6)\r\n",
        "  p6 = Dropout(dropout)(p6)\r\n",
        "\r\n",
        "  c7 = conv_2d_block(p6,n_filters*64,conv_k_size,batchnorm)\r\n",
        " \r\n",
        "\r\n",
        "  a =  tf.keras.layers.UpSampling2D(size=(8, 8), interpolation=\"nearest\")(c7)\r\n",
        "\r\n",
        "  c8 = conv_2d_block(a,n_filters*32,conv_k_size,batchnorm)  \r\n",
        "\r\n",
        "\r\n",
        "  return c8\r\n",
        "\r\n",
        "\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpwuxPyZHK23",
        "outputId": "84be37d5-9b89-4263-e57b-b460d474b0ac"
      },
      "source": [
        "clothing_encoder(arr1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 16, 16, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ9kRIEhPzfv"
      },
      "source": [
        "arr2 = np.random.randn(1,128,128,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWgQtAzSPzi_"
      },
      "source": [
        "def pose_encoder(inputs,n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\r\n",
        "  c01 = conv_2d_block(inputs,n_filters*1,conv_k_size,batchnorm)  \r\n",
        "  p01 = MaxPool2D(pool_size=(pool_size,pool_size))(c01)\r\n",
        "  p01 = Dropout(dropout)(p01)\r\n",
        "  \r\n",
        "  c02 = conv_2d_block(p01,n_filters*2,conv_k_size,batchnorm)  \r\n",
        "  p02 = MaxPool2D(pool_size=(pool_size,pool_size))(c02)\r\n",
        "  p02 = Dropout(dropout)(p02)\r\n",
        "\r\n",
        "  c03 = conv_2d_block(p02,n_filters*4,conv_k_size,batchnorm)  \r\n",
        "  p03 = MaxPool2D(pool_size=(pool_size,pool_size))(c03)\r\n",
        "  p03 = Dropout(dropout)(p03)\r\n",
        "\r\n",
        "  c04 = conv_2d_block(p03,n_filters*8,conv_k_size,batchnorm)  \r\n",
        " \r\n",
        "\r\n",
        "  c05 = conv_2d_block(c04,n_filters*16,conv_k_size,batchnorm)  \r\n",
        "  \r\n",
        "\r\n",
        "  c06 = conv_2d_block(c05,n_filters*32,conv_k_size,batchnorm)\r\n",
        " \r\n",
        "  return c06\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gox6VZVePzlV",
        "outputId": "996dd98f-7f0b-4671-bb5d-99a1e5f7d794"
      },
      "source": [
        "pose_encoder(arr2).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 16, 16, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S48xy3355WB"
      },
      "source": [
        "b = tf.keras.layers.concatenate([clothing_encoder(arr1),pose_encoder(arr2)])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNJzEUhs55gP",
        "outputId": "cb4cbc05-e28d-48b3-bbaa-cc1dd9940ee2"
      },
      "source": [
        "  b.shape\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 16, 16, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2orS3bl55jZ"
      },
      "source": [
        "def res_identity(x, filters): \r\n",
        "  #renet block where dimension doesnot change.\r\n",
        "  #The skip connection is just simple identity conncection\r\n",
        "  #we will have 3 blocks and then input will be added\r\n",
        "\r\n",
        "  x_skip = x # this will be used for addition with the residual block \r\n",
        "  f1, f2 = filters\r\n",
        "\r\n",
        "  #first block \r\n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "\r\n",
        "  #second block # bottleneck (but size kept same with padding)\r\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same' )(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "\r\n",
        "  # third block activation used after adding the input\r\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  # x = Activation('relu')(x)\r\n",
        "  \r\n",
        "  # add the input \r\n",
        "  x = Add()([x, x_skip])\r\n",
        "  x = Activation('relu')(x)\r\n",
        "\r\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ6pY6F0MSEd",
        "outputId": "854e2439-cfe2-41b9-f69a-59e34386b250"
      },
      "source": [
        "res_identity(b,(64,1024)).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 16, 16, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9h16Hw6PJVG"
      },
      "source": [
        "def res_conv(x, s, filters):\r\n",
        "  '''\r\n",
        "  here the input size changes''' \r\n",
        "  x_skip = x\r\n",
        "  f1, f2 = filters\r\n",
        "\r\n",
        "  # first block\r\n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\r\n",
        "  # when s = 2 then it is like downsizing the feature map\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "\r\n",
        "  # second block\r\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "\r\n",
        "  #third block\r\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "\r\n",
        "  # shortcut \r\n",
        "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\r\n",
        "  x_skip = BatchNormalization()(x_skip)\r\n",
        "\r\n",
        "  # add \r\n",
        "  x = Add()([x, x_skip])\r\n",
        "  x = Activation('relu')(x)\r\n",
        "\r\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JMOX-0JPMom"
      },
      "source": [
        "c = res_conv(b,1,(64,512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrPLp2U-Rtg3",
        "outputId": "922ce1df-1494-4292-9d8b-39e8f6da00b0"
      },
      "source": [
        "c.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 16, 16, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSFJadmoQsu_"
      },
      "source": [
        "#cloth decoder \r\n",
        "def clothing_decoder(inputs,n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\r\n",
        "  u6 = Conv2DTranspose(filters=n_filters *16 ,kernel_size=(3,3), strides=(2,2),padding='same')(c)\r\n",
        "  u6 = Dropout(dropout)(u6)\r\n",
        "  c7 = conv_2d_block(u6,n_filters *16 , conv_k_size,batchnorm)\r\n",
        "\r\n",
        "  u7 = Conv2DTranspose(filters=n_filters *8,kernel_size=(3,3), strides=(2,2),padding='same')(c7)\r\n",
        "  u7 = Dropout(dropout)(u7)\r\n",
        "  c8 = conv_2d_block(u7,n_filters *8 , conv_k_size,batchnorm)\r\n",
        "\r\n",
        "  u8 = Conv2DTranspose(filters=n_filters *4,kernel_size=(3,3), strides=(2,2),padding='same')(c8)\r\n",
        "  u8 = Dropout(dropout)(u8)\r\n",
        "  c9 = conv_2d_block(u8,n_filters *4, conv_k_size,batchnorm)\r\n",
        "\r\n",
        "  c10 = Conv2D(filters=18, kernel_size=(1,1),activation='softmax')(c9)\r\n",
        "  \r\n",
        "  return c10\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZHub6xXWXwC"
      },
      "source": [
        "d =  clothing_decoder(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqZ_LqyeWl1m",
        "outputId": "b855e04c-c761-44d7-eaae-3324d1fe867b"
      },
      "source": [
        "d.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 128, 128, 18])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDyu9I5GAb6_"
      },
      "source": [
        "def resnet50():\r\n",
        "\r\n",
        "  input_im = Input(shape=(train_im.shape[1], train_im.shape[2], train_im.shape[3])) # cifar 10 images size\r\n",
        "  x = ZeroPadding2D(padding=(3, 3))(input_im)\r\n",
        "\r\n",
        "  # 1st stage\r\n",
        "  # here we perform maxpooling, see the figure above\r\n",
        "\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation(activations.relu)(x)\r\n",
        "\r\n",
        "\r\n",
        "  #2nd stage \r\n",
        "  # frm here on only conv block and identity block, no pooling\r\n",
        "\r\n",
        "  x = res_identity(x, filters=(64, 256))\r\n",
        "  x = res_identity(x, filters=(64, 256))\r\n",
        "\r\n",
        "  # 3rd stage\r\n",
        "\r\n",
        "  x = res_identity(x, filters=(128, 512))\r\n",
        "  x = res_identity(x, filters=(128, 512))\r\n",
        "  x = res_identity(x, filters=(128, 512))\r\n",
        "\r\n",
        "  # 4th stage\r\n",
        "\r\n",
        "  x = res_identity(x, filters=(256, 1024))\r\n",
        "  x = res_identity(x, filters=(256, 1024))\r\n",
        "  x = res_identity(x, filters=(256, 1024))\r\n",
        "  x = res_identity(x, filters=(256, 1024))\r\n",
        "  x = res_identity(x, filters=(256, 1024))\r\n",
        "\r\n",
        "  # 5th stage\r\n",
        "\r\n",
        "  x = res_identity(x, filters=(512, 2048))\r\n",
        "  x = res_identity(x, filters=(512, 2048))\r\n",
        "\r\n",
        "  # ends with average pooling and dense connection\r\n",
        "\r\n",
        "  x = AveragePooling2D((2, 2), padding='same')(x)\r\n",
        "\r\n",
        "  x = Flatten()(x)\r\n",
        "  x = Dense(len(class_types), activation='softmax', kernel_initializer='he_normal')(x) #multi-class\r\n",
        "\r\n",
        "  # define the model \r\n",
        "\r\n",
        "  model = Model(inputs=input_im, outputs=x, name='Resnet50')\r\n",
        "\r\n",
        "  return model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}