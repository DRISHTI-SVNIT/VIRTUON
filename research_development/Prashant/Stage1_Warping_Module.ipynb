{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Warping_Module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunparmar/VIRTUON/blob/main/Prashant/Stage1_Warping_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gniOyhXl-nCW"
      },
      "source": [
        "#!pip install --upgrade neural_structured_learning"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA1f3kALJhM9",
        "outputId": "275589cd-ed79-4704-b840-ad811c61d2e5"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1F0RBiQrb-8"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.layers import Conv2D, concatenate, Dropout,MaxPool2D, MaxPooling2D, Conv2DTranspose, Activation, BatchNormalization,UpSampling2D, Add\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "import neural_structured_learning as nsl"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7J_YG27s5Br"
      },
      "source": [
        "im_height, im_width, im_channels = (128,128,3)\n",
        "n_classes = 20"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N39b2jhvvF7"
      },
      "source": [
        "#Build the model\n",
        "def conv_2d_block (x,n_filters,k_size,batchnorm = False):\n",
        "#1st layer\n",
        "  x= Conv2D(filters=n_filters,kernel_size=(k_size,k_size) ,padding='same', kernel_initializer = 'he_normal')(x)\n",
        "  if batchnorm:\n",
        "    x= BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "#2nd Layer\n",
        "  x= Conv2D(filters=n_filters,kernel_size=(k_size,k_size) ,padding='same', kernel_initializer = 'he_normal')(x)\n",
        "  if batchnorm:\n",
        "    x= BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVaPXi5tsl3h"
      },
      "source": [
        "def clothing_encoder(inputs, n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\n",
        "\n",
        "  c1 = conv_2d_block(inputs,n_filters*1,conv_k_size,batchnorm)  \n",
        "  p1 = MaxPool2D(pool_size=(pool_size,pool_size))(c1)\n",
        "  p1 = Dropout(dropout)(p1)\n",
        "  \n",
        "  c2 = conv_2d_block(p1,n_filters*2,conv_k_size,batchnorm)  \n",
        "  p2 = MaxPool2D(pool_size=(pool_size,pool_size))(c2)\n",
        "  p2 = Dropout(dropout)(p2)\n",
        "\n",
        "  c3 = conv_2d_block(p2,n_filters*4,conv_k_size,batchnorm)  \n",
        "  p3 = MaxPool2D(pool_size=(pool_size,pool_size))(c3)\n",
        "  p3 = Dropout(dropout)(p3)\n",
        "\n",
        "  c4 = conv_2d_block(p3,n_filters*8,conv_k_size,batchnorm)  \n",
        "  p4 = MaxPool2D(pool_size=(pool_size,pool_size))(c4)\n",
        "  p4 = Dropout(dropout)(p4)\n",
        "\n",
        "  c5 = conv_2d_block(p4,n_filters*16,conv_k_size,batchnorm)  \n",
        "  p5 = MaxPool2D(pool_size=(pool_size,pool_size))(c5)\n",
        "  p5 = Dropout(dropout)(p5)\n",
        "\n",
        "  c6 = conv_2d_block(p5,n_filters*32,conv_k_size,batchnorm)  \n",
        "  p6 = MaxPool2D(pool_size=(pool_size,pool_size))(c6)\n",
        "  p6 = Dropout(dropout)(p6)\n",
        "\n",
        "  c7 = conv_2d_block(p6,n_filters*64,conv_k_size,batchnorm)\n",
        " \n",
        "\n",
        "  a =  tf.keras.layers.UpSampling2D(size=(8, 8), interpolation=\"nearest\")(c7)\n",
        "\n",
        "  c8 = conv_2d_block(a,n_filters*32,conv_k_size,batchnorm)  \n",
        "\n",
        "\n",
        "  return c8"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qLVFA2jteK_"
      },
      "source": [
        "def pose_encoder(inputs, n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\n",
        "\n",
        "  c01 = conv_2d_block(inputs,n_filters*1,conv_k_size,batchnorm)  \n",
        "  p01 = MaxPool2D(pool_size=(pool_size,pool_size))(c01)\n",
        "  p01 = Dropout(dropout)(p01)\n",
        "  \n",
        "  c02 = conv_2d_block(p01,n_filters*2,conv_k_size,batchnorm)  \n",
        "  p02 = MaxPool2D(pool_size=(pool_size,pool_size))(c02)\n",
        "  p02 = Dropout(dropout)(p02)\n",
        "\n",
        "  c03 = conv_2d_block(p02,n_filters*4,conv_k_size,batchnorm)  \n",
        "  p03 = MaxPool2D(pool_size=(pool_size,pool_size))(c03)\n",
        "  p03 = Dropout(dropout)(p03)\n",
        "\n",
        "  c04 = conv_2d_block(p03,n_filters*8,conv_k_size,batchnorm)  \n",
        " \n",
        "\n",
        "  c05 = conv_2d_block(c04,n_filters*16,conv_k_size,batchnorm)  \n",
        "  \n",
        "\n",
        "  c06 = conv_2d_block(c05,n_filters*32,conv_k_size,batchnorm)\n",
        " \n",
        "  return c06"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jidBA0it83E"
      },
      "source": [
        "def res_identity(x, filters): \n",
        "  #renet block where dimension doesnot change.\n",
        "  #The skip connection is just simple identity conncection\n",
        "  #we will have 3 blocks and then input will be added\n",
        "\n",
        "  x_skip = x # this will be used for addition with the residual block \n",
        "  f1, f2 = filters\n",
        "\n",
        "  #first block \n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  #second block # bottleneck (but size kept same with padding)\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same' )(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # third block activation used after adding the input\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  # x = Activation('relu')(x)\n",
        "  \n",
        "  # add the input \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def res_conv(x, s, filters):\n",
        "  '''\n",
        "  here the input size changes''' \n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "\n",
        "  # first block\n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n",
        "  # when s = 2 then it is like downsizing the feature map\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # second block\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # shortcut \n",
        "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n",
        "  x_skip = BatchNormalization()(x_skip)\n",
        "\n",
        "  # add \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pRVVzUHuOfF"
      },
      "source": [
        "def res_block(x, s, filters):\n",
        "\n",
        "  # input_im = Input(shape=(x.shape[1], x.shape[2], x.shape[3])) # cifar 10 images size\n",
        "  # x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
        "\n",
        "  # # 1st stage\n",
        "  # # here we perform maxpooling, see the figure above\n",
        "\n",
        "  # x = BatchNormalization()(x)\n",
        "  # x = Activation(activations.relu)(x)\n",
        "\n",
        "\n",
        "  #2nd stage \n",
        "  # frm here on only conv block and identity block, no pooling\n",
        "  x = res_conv(x, s, filters)\n",
        "  x = res_identity(x, filters=(64, 512))\n",
        "  x = res_identity(x, filters=(64, 512))\n",
        "\n",
        "  # 3rd stage\n",
        "\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "\n",
        "\n",
        "  # 4th stage\n",
        "\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "\n",
        "  # 5th stage\n",
        "\n",
        "  x = res_identity(x, filters=(512, 512))\n",
        "  x = res_identity(x, filters=(512, 512))\n",
        "\n",
        "  # ends with average pooling and dense connection\n",
        "\n",
        "  # x = AveragePooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "  # x = Flatten()(x)\n",
        "  # x = Dense(len(class_types), activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n",
        "\n",
        "  return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbr9wvAoumqQ"
      },
      "source": [
        "#cloth decoder \n",
        "def clothing_decoder(inputs,n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\n",
        "  u6 = Conv2DTranspose(filters=n_filters *16 ,kernel_size=(3,3), strides=(2,2),padding='same')(inputs)\n",
        "  u6 = Dropout(dropout)(u6)\n",
        "  c7 = conv_2d_block(u6,n_filters *16 , conv_k_size,batchnorm)\n",
        "\n",
        "  u7 = Conv2DTranspose(filters=n_filters *8,kernel_size=(3,3), strides=(2,2),padding='same')(c7)\n",
        "  u7 = Dropout(dropout)(u7)\n",
        "  c8 = conv_2d_block(u7,n_filters *8 , conv_k_size,batchnorm)\n",
        "\n",
        "  u8 = Conv2DTranspose(filters=n_filters *4,kernel_size=(3,3), strides=(2,2),padding='same')(c8)\n",
        "  u8 = Dropout(dropout)(u8)\n",
        "  c9 = conv_2d_block(u8,n_filters *4, conv_k_size,batchnorm)\n",
        "\n",
        "  c10 = Conv2D(filters=n_classes, kernel_size=(1,1),activation='softmax')(c9)\n",
        "  \n",
        "  return c10"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAX2Lyknrlea"
      },
      "source": [
        "def warp(cloth_input, pose_input):\n",
        "    cloth = clothing_encoder(cloth_input)\n",
        "    pose = pose_encoder(pose_input)\n",
        "    both = concatenate([cloth, pose])\n",
        "    resnet = res_block(both, 1, (64,512))\n",
        "    output = clothing_decoder(resnet)\n",
        "\n",
        "    return Model(inputs = (cloth_input, pose_input), outputs = output, name = \"Warping_Module\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnFiS4IRyD-m"
      },
      "source": [
        "cloth = Input((im_height, im_width, n_classes), name = \"cloth\")\n",
        "pose = Input((im_height, im_width, im_channels), name = 'pose')\n",
        "test = warp(cloth, pose)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyes32-2Ikhe",
        "outputId": "ad265ab3-8361-46e0-e6d5-4fd2dacdee86"
      },
      "source": [
        "type(test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.engine.functional.Functional"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oV-lq_myqEb"
      },
      "source": [
        "#test.summary()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1273jPyunU8"
      },
      "source": [
        "x_train_pos = np.load(\"/content/drive/Shareddrives/Virtuon/Clothing Coparsing/dataset/pos_train.npy\")\r\n",
        "x_train_seg = np.load(\"/content/drive/Shareddrives/Virtuon/Clothing Coparsing/dataset/seg_train_argmax.npy\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8uQHjEovwT6"
      },
      "source": [
        "x_train_seg_1 = tf.one_hot(x_train_seg, depth = n_classes)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFMpXWI11Ppm"
      },
      "source": [
        "IMG_SIZE = 128\r\n",
        "\r\n",
        "data_augmentation = tf.keras.Sequential([\r\n",
        "  tf.keras.layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\r\n",
        "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\r\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\r\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\r\n",
        "  tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\r\n",
        "#   tf.keras.layers.experimental.preprocessing.RandomCrop(0.2,0.2)\r\n",
        "])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhbr94h67Zoh"
      },
      "source": [
        "# plt.imshow(tf.math.argmax(data_augmentation(x_train_seg_1[10:11])[0], axis = -1))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xERBJ6aqyutz"
      },
      "source": [
        "def preprocessing(pos, seg):\r\n",
        "    seg_1 = data_augmentation(seg)\r\n",
        "    return (seg_1, pos), seg"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRV4hSFQxrmj"
      },
      "source": [
        "train = tf.data.Dataset.from_tensor_slices((x_train_pos, x_train_seg_1))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT9gUGDFK48U"
      },
      "source": [
        "#train = train.batch(8).repeat()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLrNEdAlRMzk"
      },
      "source": [
        "train = train.map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bmzJoQUy9Rp"
      },
      "source": [
        "def adversarial_loss(x, y, model, loss_fn):      \r\n",
        "      labeled_loss = loss_fn(y, x)\r\n",
        "      adv_loss = nsl.keras.adversarial_loss(\r\n",
        "          x, y, model, loss_fn, labeled_loss=labeled_loss)\r\n",
        "      total_loss = labeled_loss + adv_loss\r\n",
        "return\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abogTXck2w5e"
      },
      "source": [
        "optimizer = 'Adam'\n",
        "loss = adversarial_loss( test.predict , y, test , loss_fn)\n",
        "metrics = ['accuracy']\n",
        "\n",
        "test.compile(optimizer = optimizer, loss = loss, metrics = metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi8t61_yzzqe"
      },
      "source": [
        "test.fit(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAq309dC4MOo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}