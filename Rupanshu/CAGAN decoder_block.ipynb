{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CAGAN  decoder block.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvBkeb+ToFObKqszZ3zZvA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunparmar/VIRTUON/blob/main/Rupanshu/CAGAN%20decoder_block.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm8PeJunBwDx"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib as plt\r\n",
        "import tensorflow_addons as tfa\r\n",
        "from tensorflow import keras \r\n",
        "from tensorflow.keras.layers import  concatenate, Conv2DTranspose, ReLU\r\n",
        "from tensorflow_addons.layers import InstanceNormalization"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmcswOFwNgpm"
      },
      "source": [
        "a = np.random.rand(1,128,128,18)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viCc85KDJaR9"
      },
      "source": [
        "def decoder_block(inputs,n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\r\n",
        "  u1 = Conv2DTranspose(filters=n_filters *16 ,kernel_size=(4,4), strides=(2,2),padding='same')(a)\r\n",
        "  u2 = tfa.layers.InstanceNormalization(axis=3, \r\n",
        "                                   center=True, \r\n",
        "                                   scale=True,\r\n",
        "                                   beta_initializer=\"random_uniform\",\r\n",
        "                                   gamma_initializer=\"random_uniform\")(u1)\r\n",
        "  u3 = tf.keras.layers.concatenate([u1,u2])\r\n",
        "  u4 = tf.keras.layers.ReLU(u3)\r\n",
        "\r\n",
        "  u5 = Conv2DTranspose(filters=n_filters *8,kernel_size=(4,4), strides=(2,2),padding='same')(u4)\r\n",
        "  u6 = tfa.layers.InstanceNormalization(axis=3, \r\n",
        "                                   center=True, \r\n",
        "                                   scale=True,\r\n",
        "                                   beta_initializer=\"random_uniform\",\r\n",
        "                                   gamma_initializer=\"random_uniform\")(u5)\r\n",
        "  u7 = tf.keras.layers.concatenate([u5,u6])\r\n",
        "  u8 = tf.keras.layers.ReLU(u7)\r\n",
        "\r\n",
        "  u9 = Conv2DTranspose(filters=n_filters *4,kernel_size=(4,4), strides=(2,2),padding='same')(u8)\r\n",
        "  u10 = tfa.layers.InstanceNormalization(axis=3, \r\n",
        "                                    center=True, \r\n",
        "                                    scale=True,\r\n",
        "                                    beta_initializer=\"random_uniform\",\r\n",
        "                                    gamma_initializer=\"random_uniform\")(u9)\r\n",
        "  u11 = tf.keras.layers.concatenate([u9,u10])\r\n",
        "  u12 = tf.keras.layers.ReLU(u11)\r\n",
        "\r\n",
        "  u13 = Conv2DTranspose(filters=n_filters *2 ,kernel_size=(2,2), strides=(2,2),padding='same')(u12)\r\n",
        "\r\n",
        "  return u13\r\n",
        "                                   \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        " "
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}