{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Warping_Module.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPL1dgz0K0PgY1wLLTR+ttb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjunparmar/VIRTUON/blob/main/Harshit/Warping_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1F0RBiQrb-8"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib as plt\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras.layers import Conv2D, concatenate, Dropout,MaxPool2D, MaxPooling2D, Conv2DTranspose, Activation, BatchNormalization,UpSampling2D, Add\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7J_YG27s5Br"
      },
      "source": [
        "im_height, im_width, im_channels = (128,128,3)\n",
        "n_classes = 20"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N39b2jhvvF7"
      },
      "source": [
        "#Build the model\n",
        "def conv_2d_block (x,n_filters,k_size,batchnorm = False):\n",
        "#1st layer\n",
        "  x= Conv2D(filters=n_filters,kernel_size=(k_size,k_size) ,padding='same', kernel_initializer = 'he_normal')(x)\n",
        "  if batchnorm:\n",
        "    x= BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "#2nd Layer\n",
        "  x= Conv2D(filters=n_filters,kernel_size=(k_size,k_size) ,padding='same', kernel_initializer = 'he_normal')(x)\n",
        "  if batchnorm:\n",
        "    x= BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVaPXi5tsl3h"
      },
      "source": [
        "def clothing_encoder(inputs, n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\n",
        "\n",
        "  c1 = conv_2d_block(inputs,n_filters*1,conv_k_size,batchnorm)  \n",
        "  p1 = MaxPool2D(pool_size=(pool_size,pool_size))(c1)\n",
        "  p1 = Dropout(dropout)(p1)\n",
        "  \n",
        "  c2 = conv_2d_block(p1,n_filters*2,conv_k_size,batchnorm)  \n",
        "  p2 = MaxPool2D(pool_size=(pool_size,pool_size))(c2)\n",
        "  p2 = Dropout(dropout)(p2)\n",
        "\n",
        "  c3 = conv_2d_block(p2,n_filters*4,conv_k_size,batchnorm)  \n",
        "  p3 = MaxPool2D(pool_size=(pool_size,pool_size))(c3)\n",
        "  p3 = Dropout(dropout)(p3)\n",
        "\n",
        "  c4 = conv_2d_block(p3,n_filters*8,conv_k_size,batchnorm)  \n",
        "  p4 = MaxPool2D(pool_size=(pool_size,pool_size))(c4)\n",
        "  p4 = Dropout(dropout)(p4)\n",
        "\n",
        "  c5 = conv_2d_block(p4,n_filters*16,conv_k_size,batchnorm)  \n",
        "  p5 = MaxPool2D(pool_size=(pool_size,pool_size))(c5)\n",
        "  p5 = Dropout(dropout)(p5)\n",
        "\n",
        "  c6 = conv_2d_block(p5,n_filters*32,conv_k_size,batchnorm)  \n",
        "  p6 = MaxPool2D(pool_size=(pool_size,pool_size))(c6)\n",
        "  p6 = Dropout(dropout)(p6)\n",
        "\n",
        "  c7 = conv_2d_block(p6,n_filters*64,conv_k_size,batchnorm)\n",
        " \n",
        "\n",
        "  a =  tf.keras.layers.UpSampling2D(size=(8, 8), interpolation=\"nearest\")(c7)\n",
        "\n",
        "  c8 = conv_2d_block(a,n_filters*32,conv_k_size,batchnorm)  \n",
        "\n",
        "\n",
        "  return c8"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qLVFA2jteK_"
      },
      "source": [
        "def pose_encoder(inputs, n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\n",
        "\n",
        "  c01 = conv_2d_block(inputs,n_filters*1,conv_k_size,batchnorm)  \n",
        "  p01 = MaxPool2D(pool_size=(pool_size,pool_size))(c01)\n",
        "  p01 = Dropout(dropout)(p01)\n",
        "  \n",
        "  c02 = conv_2d_block(p01,n_filters*2,conv_k_size,batchnorm)  \n",
        "  p02 = MaxPool2D(pool_size=(pool_size,pool_size))(c02)\n",
        "  p02 = Dropout(dropout)(p02)\n",
        "\n",
        "  c03 = conv_2d_block(p02,n_filters*4,conv_k_size,batchnorm)  \n",
        "  p03 = MaxPool2D(pool_size=(pool_size,pool_size))(c03)\n",
        "  p03 = Dropout(dropout)(p03)\n",
        "\n",
        "  c04 = conv_2d_block(p03,n_filters*8,conv_k_size,batchnorm)  \n",
        " \n",
        "\n",
        "  c05 = conv_2d_block(c04,n_filters*16,conv_k_size,batchnorm)  \n",
        "  \n",
        "\n",
        "  c06 = conv_2d_block(c05,n_filters*32,conv_k_size,batchnorm)\n",
        " \n",
        "  return c06"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jidBA0it83E"
      },
      "source": [
        "def res_identity(x, filters): \n",
        "  #renet block where dimension doesnot change.\n",
        "  #The skip connection is just simple identity conncection\n",
        "  #we will have 3 blocks and then input will be added\n",
        "\n",
        "  x_skip = x # this will be used for addition with the residual block \n",
        "  f1, f2 = filters\n",
        "\n",
        "  #first block \n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  #second block # bottleneck (but size kept same with padding)\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same' )(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # third block activation used after adding the input\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  # x = Activation('relu')(x)\n",
        "  \n",
        "  # add the input \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def res_conv(x, s, filters):\n",
        "  '''\n",
        "  here the input size changes''' \n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "\n",
        "  # first block\n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid')(x)\n",
        "  # when s = 2 then it is like downsizing the feature map\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  # second block\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # shortcut \n",
        "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid')(x_skip)\n",
        "  x_skip = BatchNormalization()(x_skip)\n",
        "\n",
        "  # add \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pRVVzUHuOfF"
      },
      "source": [
        "def res_block(x, s, filters):\n",
        "\n",
        "  # input_im = Input(shape=(x.shape[1], x.shape[2], x.shape[3])) # cifar 10 images size\n",
        "  # x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
        "\n",
        "  # # 1st stage\n",
        "  # # here we perform maxpooling, see the figure above\n",
        "\n",
        "  # x = BatchNormalization()(x)\n",
        "  # x = Activation(activations.relu)(x)\n",
        "\n",
        "\n",
        "  #2nd stage \n",
        "  # frm here on only conv block and identity block, no pooling\n",
        "  x = res_conv(x, s, filters)\n",
        "  x = res_identity(x, filters=(64, 512))\n",
        "  x = res_identity(x, filters=(64, 512))\n",
        "\n",
        "  # 3rd stage\n",
        "\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "\n",
        "\n",
        "  # 4th stage\n",
        "\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "  x = res_identity(x, filters=(256, 512))\n",
        "\n",
        "  # 5th stage\n",
        "\n",
        "  x = res_identity(x, filters=(512, 512))\n",
        "  x = res_identity(x, filters=(512, 512))\n",
        "\n",
        "  # ends with average pooling and dense connection\n",
        "\n",
        "  # x = AveragePooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "  # x = Flatten()(x)\n",
        "  # x = Dense(len(class_types), activation='softmax', kernel_initializer='he_normal')(x) #multi-class\n",
        "\n",
        "  return x"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbr9wvAoumqQ"
      },
      "source": [
        "#cloth decoder \n",
        "def clothing_decoder(inputs,n_filters=16,conv_k_size=3,pool_size=2,batchnorm=True,dropout=.2):\n",
        "  u6 = Conv2DTranspose(filters=n_filters *16 ,kernel_size=(3,3), strides=(2,2),padding='same')(inputs)\n",
        "  u6 = Dropout(dropout)(u6)\n",
        "  c7 = conv_2d_block(u6,n_filters *16 , conv_k_size,batchnorm)\n",
        "\n",
        "  u7 = Conv2DTranspose(filters=n_filters *8,kernel_size=(3,3), strides=(2,2),padding='same')(c7)\n",
        "  u7 = Dropout(dropout)(u7)\n",
        "  c8 = conv_2d_block(u7,n_filters *8 , conv_k_size,batchnorm)\n",
        "\n",
        "  u8 = Conv2DTranspose(filters=n_filters *4,kernel_size=(3,3), strides=(2,2),padding='same')(c8)\n",
        "  u8 = Dropout(dropout)(u8)\n",
        "  c9 = conv_2d_block(u8,n_filters *4, conv_k_size,batchnorm)\n",
        "\n",
        "  c10 = Conv2D(filters=n_classes, kernel_size=(1,1),activation='softmax')(c9)\n",
        "  \n",
        "  return c10"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAX2Lyknrlea"
      },
      "source": [
        "def warp(cloth_input, pose_input):\n",
        "    cloth = clothing_encoder(cloth_input)\n",
        "    pose = pose_encoder(pose_input)\n",
        "    both = concatenate([cloth, pose])\n",
        "    resnet = res_block(both, 1, (64,512))\n",
        "    output = clothing_decoder(resnet)\n",
        "\n",
        "    return Model(inputs = (cloth_input, pose_input), outputs = output, name = \"Warping_Module\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnFiS4IRyD-m"
      },
      "source": [
        "cloth = Input((im_height, im_width, n_classes), name = \"cloth\")\n",
        "pose = Input((im_height, im_width, im_channels), name = 'pose')\n",
        "test = warp(cloth, pose)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oV-lq_myqEb",
        "outputId": "fb810ffe-e501-476f-8fee-033c7c4b9457"
      },
      "source": [
        "test.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Warping_Module\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "cloth (InputLayer)              [(None, 128, 128, 20 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, 128, 128, 16) 2896        cloth[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, 128, 128, 16) 64          conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, 128, 128, 16) 0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, 128, 128, 16) 2320        activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, 128, 128, 16) 64          conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, 128, 128, 16) 0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling2D) (None, 64, 64, 16)   0           activation_209[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_39 (Dropout)            (None, 64, 64, 16)   0           max_pooling2d_37[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, 64, 64, 32)   4640        dropout_39[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, 64, 64, 32)   128         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, 64, 64, 32)   0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, 64, 64, 32)   9248        activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, 64, 64, 32)   128         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, 64, 64, 32)   0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_38 (MaxPooling2D) (None, 32, 32, 32)   0           activation_211[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 32, 32, 32)   0           max_pooling2d_38[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, 32, 32, 64)   18496       dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, 32, 32, 64)   256         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, 32, 32, 64)   0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "pose (InputLayer)               [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, 32, 32, 64)   36928       activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, 128, 128, 16) 448         pose[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, 32, 32, 64)   256         conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, 128, 128, 16) 64          conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, 32, 32, 64)   0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, 128, 128, 16) 0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_39 (MaxPooling2D) (None, 16, 16, 64)   0           activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, 128, 128, 16) 2320        activation_224[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_41 (Dropout)            (None, 16, 16, 64)   0           max_pooling2d_39[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, 128, 128, 16) 64          conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, 16, 16, 128)  73856       dropout_41[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, 128, 128, 16) 0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, 16, 16, 128)  512         conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling2D) (None, 64, 64, 16)   0           activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, 16, 16, 128)  0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_45 (Dropout)            (None, 64, 64, 16)   0           max_pooling2d_43[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, 16, 16, 128)  147584      activation_214[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, 64, 64, 32)   4640        dropout_45[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, 16, 16, 128)  512         conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, 64, 64, 32)   128         conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, 16, 16, 128)  0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, 64, 64, 32)   0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling2D) (None, 8, 8, 128)    0           activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, 64, 64, 32)   9248        activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_42 (Dropout)            (None, 8, 8, 128)    0           max_pooling2d_40[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, 64, 64, 32)   128         conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, 8, 8, 256)    295168      dropout_42[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, 64, 64, 32)   0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, 8, 8, 256)    1024        conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_44 (MaxPooling2D) (None, 32, 32, 32)   0           activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, 8, 8, 256)    0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_46 (Dropout)            (None, 32, 32, 32)   0           max_pooling2d_44[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, 8, 8, 256)    590080      activation_216[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, 32, 32, 64)   18496       dropout_46[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, 8, 8, 256)    1024        conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, 32, 32, 64)   256         conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, 8, 8, 256)    0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, 32, 32, 64)   0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling2D) (None, 4, 4, 256)    0           activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, 32, 32, 64)   36928       activation_228[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 4, 4, 256)    0           max_pooling2d_41[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, 32, 32, 64)   256         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, 4, 4, 512)    1180160     dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, 32, 32, 64)   0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, 4, 4, 512)    2048        conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_45 (MaxPooling2D) (None, 16, 16, 64)   0           activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, 4, 4, 512)    0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_47 (Dropout)            (None, 16, 16, 64)   0           max_pooling2d_45[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, 4, 4, 512)    2359808     activation_218[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, 16, 16, 128)  73856       dropout_47[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, 4, 4, 512)    2048        conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, 16, 16, 128)  512         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, 4, 4, 512)    0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, 16, 16, 128)  0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling2D) (None, 2, 2, 512)    0           activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, 16, 16, 128)  147584      activation_230[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 2, 2, 512)    0           max_pooling2d_42[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, 16, 16, 128)  512         conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, 2, 2, 1024)   4719616     dropout_44[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, 16, 16, 128)  0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, 2, 2, 1024)   4096        conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, 16, 16, 256)  295168      activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, 2, 2, 1024)   0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, 16, 16, 256)  1024        conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, 2, 2, 1024)   9438208     activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, 16, 16, 256)  0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, 2, 2, 1024)   4096        conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, 16, 16, 256)  590080      activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, 2, 2, 1024)   0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, 16, 16, 256)  1024        conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 16, 16, 1024) 0           activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, 16, 16, 256)  0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, 16, 16, 512)  4719104     up_sampling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, 16, 16, 512)  1180160     activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, 16, 16, 512)  2048        conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, 16, 16, 512)  2048        conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, 16, 16, 512)  0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, 16, 16, 512)  0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, 16, 16, 512)  2359808     activation_222[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, 16, 16, 512)  2359808     activation_234[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, 16, 16, 512)  2048        conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, 16, 16, 512)  2048        conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, 16, 16, 512)  0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, 16, 16, 512)  0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 16, 16, 1024) 0           activation_223[0][0]             \n",
            "                                                                 activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, 16, 16, 64)   65600       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, 16, 16, 64)   256         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, 16, 16, 64)   0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, 16, 16, 64)   36928       activation_236[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, 16, 16, 64)   256         conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, 16, 16, 64)   0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, 16, 16, 512)  33280       activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, 16, 16, 512)  524800      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, 16, 16, 512)  2048        conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, 16, 16, 512)  2048        conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 16, 16, 512)  0           batch_normalization_240[0][0]    \n",
            "                                                                 batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, 16, 16, 512)  0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, 16, 16, 64)   32832       activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, 16, 16, 64)   256         conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, 16, 16, 64)   0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, 16, 16, 64)   36928       activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, 16, 16, 64)   256         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, 16, 16, 64)   0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, 16, 16, 512)  33280       activation_240[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, 16, 16, 512)  2048        conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 16, 16, 512)  0           batch_normalization_244[0][0]    \n",
            "                                                                 activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, 16, 16, 512)  0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, 16, 16, 64)   32832       activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, 16, 16, 64)   256         conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, 16, 16, 64)   0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, 16, 16, 64)   36928       activation_242[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, 16, 16, 64)   256         conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, 16, 16, 64)   0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, 16, 16, 512)  33280       activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, 16, 16, 512)  2048        conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 16, 16, 512)  0           batch_normalization_247[0][0]    \n",
            "                                                                 activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, 16, 16, 512)  0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, 16, 16, 128)  65664       activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, 16, 16, 128)  512         conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, 16, 16, 128)  0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, 16, 16, 128)  147584      activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, 16, 16, 128)  512         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, 16, 16, 128)  0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, 16, 16, 512)  66048       activation_246[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, 16, 16, 512)  2048        conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 16, 16, 512)  0           batch_normalization_250[0][0]    \n",
            "                                                                 activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, 16, 16, 512)  0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, 16, 16, 128)  65664       activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, 16, 16, 128)  512         conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, 16, 16, 128)  0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, 16, 16, 128)  147584      activation_248[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, 16, 16, 128)  512         conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, 16, 16, 128)  0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, 16, 16, 512)  66048       activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, 16, 16, 512)  2048        conv2d_254[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 16, 16, 512)  0           batch_normalization_253[0][0]    \n",
            "                                                                 activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, 16, 16, 512)  0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, 16, 16, 128)  65664       activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, 16, 16, 128)  512         conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, 16, 16, 128)  0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, 16, 16, 128)  147584      activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, 16, 16, 128)  512         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, 16, 16, 128)  0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, 16, 16, 512)  66048       activation_252[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, 16, 16, 512)  2048        conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 16, 16, 512)  0           batch_normalization_256[0][0]    \n",
            "                                                                 activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, 16, 16, 512)  0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, 16, 16, 128)  65664       activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, 16, 16, 128)  512         conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, 16, 16, 128)  0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, 16, 16, 128)  147584      activation_254[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, 16, 16, 128)  512         conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, 16, 16, 128)  0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, 16, 16, 512)  66048       activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, 16, 16, 512)  2048        conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 16, 16, 512)  0           batch_normalization_259[0][0]    \n",
            "                                                                 activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, 16, 16, 512)  0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, 16, 16, 128)  65664       activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, 16, 16, 128)  512         conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, 16, 16, 128)  0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, 16, 16, 128)  147584      activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, 16, 16, 128)  512         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, 16, 16, 128)  0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, 16, 16, 512)  66048       activation_258[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, 16, 16, 512)  2048        conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 16, 16, 512)  0           batch_normalization_262[0][0]    \n",
            "                                                                 activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, 16, 16, 512)  0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, 16, 16, 128)  65664       activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, 16, 16, 128)  512         conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, 16, 16, 128)  0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, 16, 16, 128)  147584      activation_260[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, 16, 16, 128)  512         conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, 16, 16, 128)  0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, 16, 16, 512)  66048       activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, 16, 16, 512)  2048        conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 16, 16, 512)  0           batch_normalization_265[0][0]    \n",
            "                                                                 activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, 16, 16, 512)  0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, 16, 16, 256)  131328      activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, 16, 16, 256)  1024        conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, 16, 16, 256)  0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, 16, 16, 256)  590080      activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, 16, 16, 256)  1024        conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, 16, 16, 256)  0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, 16, 16, 512)  131584      activation_264[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, 16, 16, 512)  2048        conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 16, 16, 512)  0           batch_normalization_268[0][0]    \n",
            "                                                                 activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, 16, 16, 512)  0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, 16, 16, 256)  131328      activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, 16, 16, 256)  1024        conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, 16, 16, 256)  0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, 16, 16, 256)  590080      activation_266[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, 16, 16, 256)  1024        conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, 16, 16, 256)  0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, 16, 16, 512)  131584      activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, 16, 16, 512)  2048        conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 16, 16, 512)  0           batch_normalization_271[0][0]    \n",
            "                                                                 activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, 16, 16, 512)  0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, 16, 16, 256)  131328      activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, 16, 16, 256)  1024        conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, 16, 16, 256)  0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, 16, 16, 256)  590080      activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, 16, 16, 256)  1024        conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, 16, 16, 256)  0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, 16, 16, 512)  131584      activation_270[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, 16, 16, 512)  2048        conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 16, 16, 512)  0           batch_normalization_274[0][0]    \n",
            "                                                                 activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, 16, 16, 512)  0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, 16, 16, 256)  131328      activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, 16, 16, 256)  1024        conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, 16, 16, 256)  0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, 16, 16, 256)  590080      activation_272[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, 16, 16, 256)  1024        conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, 16, 16, 256)  0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, 16, 16, 512)  131584      activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, 16, 16, 512)  2048        conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 16, 16, 512)  0           batch_normalization_277[0][0]    \n",
            "                                                                 activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, 16, 16, 512)  0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, 16, 16, 256)  131328      activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, 16, 16, 256)  1024        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, 16, 16, 256)  0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, 16, 16, 256)  590080      activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, 16, 16, 256)  1024        conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, 16, 16, 256)  0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, 16, 16, 512)  131584      activation_276[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, 16, 16, 512)  2048        conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 16, 16, 512)  0           batch_normalization_280[0][0]    \n",
            "                                                                 activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, 16, 16, 512)  0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, 16, 16, 512)  262656      activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, 16, 16, 512)  2048        conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, 16, 16, 512)  0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, 16, 16, 512)  2359808     activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, 16, 16, 512)  2048        conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, 16, 16, 512)  0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, 16, 16, 512)  262656      activation_279[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, 16, 16, 512)  2048        conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 16, 16, 512)  0           batch_normalization_283[0][0]    \n",
            "                                                                 activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, 16, 16, 512)  0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, 16, 16, 512)  262656      activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 16, 16, 512)  2048        conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, 16, 16, 512)  0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, 16, 16, 512)  2359808     activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 16, 16, 512)  2048        conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, 16, 16, 512)  0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, 16, 16, 512)  262656      activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 16, 16, 512)  2048        conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 16, 16, 512)  0           batch_normalization_286[0][0]    \n",
            "                                                                 activation_280[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, 16, 16, 512)  0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 32, 32, 256)  1179904     activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_48 (Dropout)            (None, 32, 32, 256)  0           conv2d_transpose_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, 32, 32, 256)  590080      dropout_48[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 32, 32, 256)  1024        conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 32, 32, 256)  0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, 32, 32, 256)  590080      activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 32, 32, 256)  1024        conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 32, 32, 256)  0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 128)  295040      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_49 (Dropout)            (None, 64, 64, 128)  0           conv2d_transpose_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, 64, 64, 128)  147584      dropout_49[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 64, 64, 128)  512         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 64, 64, 128)  0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, 64, 64, 128)  147584      activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 64, 64, 128)  512         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 64, 64, 128)  0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 128, 128, 64) 73792       activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_50 (Dropout)            (None, 128, 128, 64) 0           conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, 128, 128, 64) 36928       dropout_50[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 128, 128, 64) 256         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 128, 128, 64) 0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, 128, 128, 64) 36928       activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 128, 128, 64) 256         conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 128, 128, 64) 0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, 128, 128, 20) 1300        activation_289[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 46,446,468\n",
            "Trainable params: 46,400,004\n",
            "Non-trainable params: 46,464\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abogTXck2w5e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi8t61_yzzqe"
      },
      "source": [
        "test.predict()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}